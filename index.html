<!DOCTYPE html>
<html lang="en">

<head>
  <link rel="shortcut icon" type="image/x-icon" href="siteicon.ico" />
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Traffic Signals Detector</title>
  <link rel="stylesheet" href="./app.css" />
</head>

<body>

  <header>
    <h1>AI Camera</h1>
  </header>

<!--<audio controls >
  <source src="stop.mp3" type="audio/mpeg">
Your browser does not support the audio element.
</audio>
-->

<audio id="redlightsound">
  <source src="redlight.mp3" type="audio/mpeg">
</audio>
<audio id="yellowlightsound">
  <source src="Yellow.mp3" type="audio/mpeg">
</audio>
<audio id="greenlightsound">
  <source src="go.mp3" type="audio/mpeg">
</audio>
<audio id="stopsignsound">
  <source src="stopsign.mp3" type="audio/mpeg">
</audio>
<audio id="donotentersignsound">
  <source src="donotenter.mp3" type="audio/mpeg">
</audio>


<script>
//var audio = new Audio('stop.mp3');  //works
 //audio.play();
var x = document.getElementById("stopsound"); //works
  //x.play(); 
</script>

  <main>
    <div class="controls">
      <select id="select">
        <option></option>
      </select>
      <button id="button">Get camera</button>
    </div>

    <div>Select camera from dropdown above and click Get camera. Then, click Start to show and start the Recognizer. Below the video, the accurary percentages of each type of case will be showned. Select a different camera, press Get camera once more, and press start again to test different cameras.</div>
    <hr>
    <div> Proballity of detection of Sign Type ðŸ‘‡</div>
       <p id="demo"></p>
    <button type="button" onclick="init()">Start</button>

    <video id="video" autoplay playsinline>

	//video {
	  width: 100%;
	  max-width: 400px;
	  //display: block;
	  //margin: 0 auto;
	//}

	</video>

  </main>

  <footer>
    <!-- <p>Built by
      <a href="https://twitter.com/philnash">@philnash</a>
    </p> -->
  </footer>

<!--  <script src="./app.js"></script> -->
<script type="text/javascript">  // app.js

const audio = document.getElementById('audio');
const video = document.getElementById('video');
const button = document.getElementById('button');
const select = document.getElementById('select');
let currentStream;

function stopMediaTracks(stream) {
  stream.getTracks().forEach(track => {
    track.stop();
  });
}

function gotDevices(mediaDevices) {
  select.innerHTML = '';
  select.appendChild(document.createElement('option'));
  let count = 1;
  mediaDevices.forEach(mediaDevice => {
    if (mediaDevice.kind === 'videoinput') {
      const option = document.createElement('option');
      option.value = mediaDevice.deviceId;
      const label = mediaDevice.label || `Camera ${count++}`;
      const textNode = document.createTextNode(label);
      option.appendChild(textNode);
      select.appendChild(option);
    }
  });
}

button.addEventListener('click', event => {
  if (typeof currentStream !== 'undefined') {
    stopMediaTracks(currentStream);
  }
  const videoConstraints = {};
  if (select.value === '') {
    videoConstraints.facingMode = 'environment';
  } else {
    videoConstraints.deviceId = { exact: select.value };
  }
  const constraints = {
    video: videoConstraints,
    audio: false
  };
  navigator.mediaDevices
    .getUserMedia(constraints)
    .then(stream => {
      currentStream = stream;
      video.srcObject = stream;
      return navigator.mediaDevices.enumerateDevices();
    })
    .then(gotDevices)
    .catch(error => {
      console.error(error);
	document.write(error);
    });
});

navigator.mediaDevices.enumerateDevices().then(gotDevices);

</script>


<div id="webcam-container"></div>
<div id="label-container"></div>

<!-- <h1 id="heading">Hello, codedamn!</h1> -->

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
<script type="text/javascript">

    // More API functions here:
    // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

    // the link to your model provided by Teachable Machine export panel
    //const URL = "https://teachablemachine.withgoogle.com/models/G4l43dOoD/";
    const URL = "https://teachablemachine.withgoogle.com/models/Ui5Bv4szM/";  

    let model, webcam, labelContainer, maxPredictions;
  let igreen = 0;
  let ired = 0;
  let iyellow = 0;
  let istop = 0;
  let ino = 0;


    // Load the image model and setup the webcam
    async function init() {
        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";
	
	devices = await navigator.mediaDevices.enumerateDevices()
  	//let name = "World";
	//document.getElementById("heading").innerHTML = devices;

        // load the model and metadata
        // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
        // or files from your local hard drive
        // Note: the pose library adds "tmImage" object to your window (window.tmImage)
        model = await tmImage.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        // Convenience function to setup a webcam
        const flip = true; // whether to flip the webcam
        //webcam = new tmImage.Webcam(400, 400, flip); // width, height, flip
	//webcam = video;
        //await webcam.setup(); // request access to the webcam
	//await webcam.setup({ facingMode: "environment" });
	//await webcam.setup({ deviceId: devices[0].deviceId });  // 0: works
	
	//await Webcam.setup({
	 //width: 640,
	 //height: 480, 
	 //image_format: 'jpeg',
	 //jpeg_quality: 800,
	 //constraints: { facingMode: 'environment' }
	//});

        //await webcam.play();
        window.requestAnimationFrame(loop);

        // append elements to the DOM
        //document.getElementById("webcam-container").appendChild(webcam.canvas);
        labelContainer = document.getElementById("label-container");
        for (let i = 0; i < maxPredictions; i++) { // and class labels
            labelContainer.appendChild(document.createElement("div"));
        }
    }

    async function loop() {
        //webcam.update(); // update the webcam frame
        await predict();
	wait(3000);
        window.requestAnimationFrame(loop);
    }

    // run the webcam image through the image model
    async function predict() {
        // predict can take in an image, video or canvas html element
        //const prediction = await model.predict(webcam.canvas);
        //const prediction = await model.predict(currentStream);  //one flame
        const prediction = await model.predict(video);  //live, front cam only

        for (let i = 0; i < maxPredictions; i++) {
            const classPrediction =
                prediction[i].className + ": " + prediction[i].probability.toFixed(2);
            labelContainer.childNodes[i].innerHTML = classPrediction;
        }
	
	//// Sound:
        document.getElementById("demo").innerHTML = parseFloat(prediction[0].probability) + "<br>";

 	if (parseFloat(prediction[0].probability) > 0.5 && istop == 0 ) {   //  if fail, will stop, need start again
    	var x = document.getElementById("stopsignsound"); //works
    	x.play();
	sign_reset();
	await delay(3000);
	//istop = 1;
  	} else if (parseFloat(prediction[1].probability) > 0.5 && ino == 0 ) {   
    	var x = document.getElementById("redlightsound"); 
    	x.play();
	sign_reset();
	ino = 1;	
	} else if (parseFloat(prediction[2].probability) > 0.5 && ino == 0 ) {   
    	var x = document.getElementById("yellowlightsound"); 
    	x.play();
	sign_reset();
	ino = 1;	
	} else if (parseFloat(prediction[3].probability) > 0.5 && ino == 0 ) {   
    	var x = document.getElementById("greenlightsound"); 
    	x.play();
	sign_reset();
	ino = 1;	
	} else if (parseFloat(prediction[4].probability) > 0.5 && ino == 0 ) {   
    	var x = document.getElementById("donotentersignsound"); 
    	x.play();
	sign_reset();
	ino = 1;	
	}

    }

function delay(milliseconds){
    return new Promise(resolve => {
        setTimeout(resolve, milliseconds);
    });
}

function wait() {  //not work
  const sleep = (delay) => new Promise((resolve) => setTimeout(resolve, delay));

  const repeatedGreetings = async () => {
  await sleep(1000);
  console.log("Wait1Sec");
  }

  repeatedGreetings();
}

function sign_reset() {
  igreen = 0;
  ired = 0;
  iyellow = 0;
  istop = 0;
  ino = 0;
}



/////////////////////
    document.getElementById("demo").innerHTML = parseFloat(prediction[0].probability) + "<br>";

  //label = "Stop Sign";
  //stopsign = 0;

  //if (parseFloat(prediction[0].probability.toFixed(2)) >= 0.0) {
  if (1==1) {
    var x = document.getElementById("stopsound"); 
    x.play;	
    wait();
    if (x.isPlaying()) { //if you want to play stop, change stopsignsound to stop.
      wait();
      console.log("Stop Sign Sound is Playing");
    } else if (stopsign == 0) {
      x.play(); //if you want to play stop, change stopsignsound to stop.
      wait();
      //sign_reset();
      stopsign = 1;
      console.log(stopsign);
    }
  }

</script>


<script src="./main.js"></script>


</body>

</html>